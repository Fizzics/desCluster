<HDF5 file "halo00.hdf5" (mode r)>
<HDF5 file "halo01.hdf5" (mode r)>
<HDF5 file "halo02.hdf5" (mode r)>
<HDF5 file "halo03.hdf5" (mode r)>
<HDF5 file "halo04.hdf5" (mode r)>
<HDF5 file "halo05.hdf5" (mode r)>
<HDF5 file "halo06.hdf5" (mode r)>
<HDF5 file "halo07.hdf5" (mode r)>
<HDF5 file "halo08.hdf5" (mode r)>
<HDF5 file "halo09.hdf5" (mode r)>
<HDF5 file "halo10.hdf5" (mode r)>
<HDF5 file "halo11.hdf5" (mode r)>
<HDF5 file "halo12.hdf5" (mode r)>
<HDF5 file "halo13.hdf5" (mode r)>
<HDF5 file "halo14.hdf5" (mode r)>
<HDF5 file "halo15.hdf5" (mode r)>
<HDF5 file "halo16.hdf5" (mode r)>
<HDF5 file "halo17.hdf5" (mode r)>
<HDF5 file "halo18.hdf5" (mode r)>
<HDF5 file "halo19.hdf5" (mode r)>
0
100000
200000
300000
400000
500000
600000
700000
800000
900000
1000000
1100000
1200000
1300000
0
100000
200000
300000
400000
500000
600000
700000
800000
900000
1000000
1100000
1200000
1300000
('do work', 1760, 'clusters to go!')
results

real	4m40.013s
user	4m32.541s
sys	0m14.316s

------------------------------------------------------------
Sender: LSF System <lsfadmin@nxt1662>
Subject: Job 2206841: <surveyObs> in cluster <Main_Compute> Done

Job <surveyObs> was submitted from host <login1> by user <boada> in cluster <Main_Compute>.
Job was executed on host(s) <20*nxt1662>, in queue <sn_regular>, as user <boada> in cluster <Main_Compute>.
</home/boada> was used as the home directory.
</home/boada/Projects/desCluster/mkSurvey> was used as the working directory.
Started at Fri Feb 12 13:39:10 2016
Results reported on Fri Feb 12 13:44:09 2016

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
## job name
#BSUB -J surveyObs

## send stderr and stdout to the same file
#BSUB -o output.%J

## login shell to avoid copying env from login session
## also helps the module function work in batch jobs
#BSUB -L /bin/bash

## 30 minutes of walltime ([HH:]MM)
#BSUB -W 2:00

## numprocs
#BSUB -n 20

## 20 cores/node
#BSUB -R 'span[ptile=20]'

source /home/boada/.bashrc
time py mkClusters.py


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   317.91 sec.
    Max Memory :                                 3777 MB
    Average Memory :                             2304.93 MB
    Total Requested Memory :                     51200.00 MB
    Delta Memory :                               47423.00 MB
    Max Processes :                              24
    Max Threads :                                28

The output (if any) is above this job summary.

