/software/lmod/5.9.3/init/lmod_bash_completions: line 22: syntax error near unexpected token `('
/software/lmod/5.9.3/init/lmod_bash_completions: line 22: `	comm -23  <(_module_avail|sort)  <(_module_loaded_modules|sort)'
/software/lmod/5.9.3/init/lmod_bash_completions: line 22: warning: syntax errors in . or eval will cause future versions of the shell to abort as Posix requires
Lmod has detected the following error: Cannot load module 
python/2.7.10-intel-2015B" because these modules are loaded:
   Python


While processing the following module(s):

Module fullname            Module Filename
---------------            ---------------
python/2.7.10-intel-2015B  /general/software/x86_64/tamusc/modulefiles/python/2.7.10-intel-2015B
<HDF5 file "halo00.hdf5" (mode r)>
<HDF5 file "halo01.hdf5" (mode r)>
<HDF5 file "halo02.hdf5" (mode r)>
<HDF5 file "halo03.hdf5" (mode r)>
<HDF5 file "halo04.hdf5" (mode r)>
<HDF5 file "halo05.hdf5" (mode r)>
<HDF5 file "halo06.hdf5" (mode r)>
<HDF5 file "halo07.hdf5" (mode r)>
<HDF5 file "halo08.hdf5" (mode r)>
<HDF5 file "halo09.hdf5" (mode r)>
<HDF5 file "halo10.hdf5" (mode r)>
<HDF5 file "halo11.hdf5" (mode r)>
<HDF5 file "halo12.hdf5" (mode r)>
<HDF5 file "halo13.hdf5" (mode r)>
<HDF5 file "halo14.hdf5" (mode r)>
<HDF5 file "halo15.hdf5" (mode r)>
<HDF5 file "halo16.hdf5" (mode r)>
<HDF5 file "halo17.hdf5" (mode r)>
<HDF5 file "halo18.hdf5" (mode r)>
<HDF5 file "halo19.hdf5" (mode r)>
0
100000
200000
300000
400000
500000
600000
700000
800000
900000
1000000
1100000
1200000
1300000
0
100000
200000
300000
400000
500000
600000
700000
800000
900000
1000000
1100000
1200000
1300000
do work
0
1000
2000
3000
results

real	8m33.409s
user	80m34.739s
sys	0m57.006s

------------------------------------------------------------
Sender: LSF System <lsfadmin@nxt1631>
Subject: Job 2164380: <surveyObs> in cluster <Main_Compute> Done

Job <surveyObs> was submitted from host <login6> by user <boada> in cluster <Main_Compute>.
Job was executed on host(s) <20*nxt1631>, in queue <sn_regular>, as user <boada> in cluster <Main_Compute>.
</home/boada> was used as the home directory.
</home/boada/Projects/desCluster/mkSurvey> was used as the working directory.
Started at Wed Jan 27 09:37:41 2016
Results reported on Wed Jan 27 09:46:31 2016

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
## job name
#BSUB -J surveyObs

## send stderr and stdout to the same file
#BSUB -o output.%J

## login shell to avoid copying env from login session
## also helps the module function work in batch jobs
#BSUB -L /bin/bash

## 30 minutes of walltime ([HH:]MM)
#BSUB -W 2:00

## numprocs
#BSUB -n 20

## 20 cores/node
#BSUB -R 'span[ptile=20]'

source /home/boada/.bashrc
time py mkClusters.py


------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   4925.26 sec.
    Max Memory :                                 4966 MB
    Average Memory :                             3016.80 MB
    Total Requested Memory :                     51200.00 MB
    Delta Memory :                               46234.00 MB
    Max Processes :                              24
    Max Threads :                                28

The output (if any) is above this job summary.

